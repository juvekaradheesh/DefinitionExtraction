{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"..\"\n",
    "all_train = \"data/classification/all/train\"\n",
    "all_val = \"data/classification/all/val\"\n",
    "all_test = \"data/classification/all/test\"\n",
    "\n",
    "w00_train = \"data/classification/w00/train\"\n",
    "w00_val = \"data/classification/w00/val\"\n",
    "\n",
    "wcl_train = \"data/classification/wcl/train\"\n",
    "wcl_val = \"data/classification/wcl/val\"\n",
    "\n",
    "openstax_train = \"data/classification/openstax/train\"\n",
    "openstax_val = \"data/classification/openstax/val\"\n",
    "openstax_test = \"data/classification/openstax/test\"\n",
    "\n",
    "deft_train = \"data/classification/deft_corpus/train\"\n",
    "deft_val = \"data/classification/deft_corpus/val\"\n",
    "deft_test = \"data/classification/deft_corpus/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_list(path):\n",
    "    list_ = []\n",
    "    f = open(path, 'r')\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        list_.append(line.replace('\\n',''))\n",
    "    f.close()\n",
    "\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82463 82463\n",
      "4619 4619\n",
      "2184 2184\n",
      "19376 19376\n"
     ]
    }
   ],
   "source": [
    "all_sents = file_to_list(ROOT_DIR + '/' + all_train + '/sentences.txt')\n",
    "all_sents.extend(file_to_list(ROOT_DIR + '/' + all_val + '/sentences.txt'))\n",
    "\n",
    "all_labels = file_to_list(ROOT_DIR + '/' + all_train + '/labels.txt')\n",
    "all_labels.extend(file_to_list(ROOT_DIR + '/' + all_val + '/labels.txt'))\n",
    "\n",
    "wcl_sents = file_to_list(ROOT_DIR + '/' + wcl_train + '/sentences.txt')\n",
    "wcl_sents.extend(file_to_list(ROOT_DIR + '/' + wcl_val + '/sentences.txt'))\n",
    "\n",
    "wcl_labels = file_to_list(ROOT_DIR + '/' + wcl_train + '/labels.txt')\n",
    "wcl_labels.extend(file_to_list(ROOT_DIR + '/' + wcl_val + '/labels.txt'))\n",
    "\n",
    "w00_sents = file_to_list(ROOT_DIR + '/' + w00_train + '/sentences.txt')\n",
    "w00_sents.extend(file_to_list(ROOT_DIR + '/' + w00_val + '/sentences.txt'))\n",
    "\n",
    "w00_labels = file_to_list(ROOT_DIR + '/' + w00_train + '/labels.txt')\n",
    "w00_labels.extend(file_to_list(ROOT_DIR + '/' + w00_val + '/labels.txt'))\n",
    "\n",
    "\n",
    "deft_sents = file_to_list(ROOT_DIR + '/' + deft_train + '/sentences.txt')\n",
    "deft_sents.extend(file_to_list(ROOT_DIR + '/' + deft_val + '/sentences.txt'))\n",
    "deft_sents.extend(file_to_list(ROOT_DIR + '/' + deft_test + '/sentences.txt'))\n",
    "\n",
    "deft_labels = file_to_list(ROOT_DIR + '/' + deft_train + '/labels.txt')\n",
    "deft_labels.extend(file_to_list(ROOT_DIR + '/' + deft_val + '/labels.txt'))\n",
    "deft_labels.extend(file_to_list(ROOT_DIR + '/' + deft_test + '/labels.txt'))\n",
    "\n",
    "\n",
    "print(len(all_sents), len(all_labels))\n",
    "print(len(wcl_sents), len(wcl_labels))\n",
    "print(len(w00_sents), len(w00_labels))\n",
    "print(len(deft_sents), len(deft_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate Openstax from all and split into train-dev-test as 60-20-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75660, 75660)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(list(set(all_sents) - set(wcl_sents) - set(w00_sents)))\n",
    "openstax_sents = []\n",
    "openstax_labels = []\n",
    "for sent, label in zip(all_sents, all_labels):\n",
    "    if sent not in wcl_sents and sent not in w00_sents:\n",
    "        openstax_sents.append(sent)\n",
    "        openstax_labels.append(label)\n",
    "\n",
    "len(openstax_sents), len(openstax_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(openstax_sents, openstax_labels, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_file(path, list_):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in list_:\n",
    "            f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45396, 15132, 15132)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_file(ROOT_DIR+'/'+openstax_train+'/sentences.txt', X_train)\n",
    "list_to_file(ROOT_DIR+'/'+openstax_train+'/labels.txt', y_train)\n",
    "\n",
    "list_to_file(ROOT_DIR+'/'+openstax_val+'/sentences.txt', X_val)\n",
    "list_to_file(ROOT_DIR+'/'+openstax_val+'/labels.txt', y_val)\n",
    "\n",
    "list_to_file(ROOT_DIR+'/'+openstax_test+'/sentences.txt', X_test)\n",
    "list_to_file(ROOT_DIR+'/'+openstax_test+'/labels.txt', y_test)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add deft corpus data to all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101839, 101839)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sents.extend(deft_sents)\n",
    "all_labels.extend(deft_labels)\n",
    "len(all_sents), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61103 20368 20368\n",
      "101839\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_val), len(X_test))\n",
    "print(len(X_train) + len(X_val) + len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10409 50694\n",
      "3493 16875\n",
      "3471 16897\n"
     ]
    }
   ],
   "source": [
    "print(y_train.count('1'), y_train.count('0'))\n",
    "print(y_val.count('1'), y_val.count('0'))\n",
    "print(y_test.count('1'), y_test.count('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61103, 20368, 20368)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_file(ROOT_DIR+'/'+all_train+'/sentences.txt', X_train)\n",
    "list_to_file(ROOT_DIR+'/'+all_train+'/labels.txt', y_train)\n",
    "\n",
    "list_to_file(ROOT_DIR+'/'+all_val+'/sentences.txt', X_val)\n",
    "list_to_file(ROOT_DIR+'/'+all_val+'/labels.txt', y_val)\n",
    "\n",
    "list_to_file(ROOT_DIR+'/'+all_test+'/sentences.txt', X_test)\n",
    "list_to_file(ROOT_DIR+'/'+all_test+'/labels.txt', y_test)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10139\n",
      "10139\n",
      "10139\n",
      "10139\n",
      "10138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10409"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_0 = [index for index, value in enumerate(y_train) if value == '0']\n",
    "indices_1 = [index for index, value in enumerate(y_train) if value == '1']\n",
    "len(indices_0)\n",
    "random.seed(SEED)\n",
    "random.shuffle(indices_0)\n",
    "\n",
    "# To split into N lists, get size of each list\n",
    "N = 5\n",
    "size_ = len(indices_0)//N + 1\n",
    "undersampled_lists = []\n",
    "\n",
    "for i in range(0, len(indices_0), size_):\n",
    "    undersampled_lists.append(indices_0[i:i+size_])\n",
    "\n",
    "for i in undersampled_lists:\n",
    "    print(len(i))\n",
    "len(indices_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20548\n",
      "20548\n",
      "20548\n",
      "20548\n",
      "20547\n"
     ]
    }
   ],
   "source": [
    "undersampling_train = \"data/classification/all/undersampling_train\"\n",
    "train_data_path = os.path.join(ROOT_DIR, undersampling_train)\n",
    "\n",
    "for i, index_list in enumerate(undersampled_lists):\n",
    "    temp_list = index_list\n",
    "    temp_list.extend(indices_1)\n",
    "    print(len(temp_list))\n",
    "    curr_sents = [X_train[j] for j in temp_list]\n",
    "    curr_labels = [y_train[j] for j in temp_list]\n",
    "    curr_path = os.path.join(train_data_path, str(i))\n",
    "    list_to_file(curr_path+'/sentences.txt', curr_sents)\n",
    "    list_to_file(curr_path+'/labels.txt', curr_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('def': conda)",
   "language": "python",
   "name": "python38264bitdefconda9691c0964b1848cda08b1f9faea2d317"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
